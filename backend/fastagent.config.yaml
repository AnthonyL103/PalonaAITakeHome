
mcp:
  servers:
    SemanticSearchServer:
      command: "uv"
      args: ["run", "/Users/anthonyli/TakeHomePalona/backend/servers/semantic_search.py"]
      
      
    
llm:
  provider: openai
  model: gpt-4.1
  reasoning_effort: high
    
execution_engine: "asyncio"

logger:
  
  progress_display: true

  show_chat: false
  show_tools: true
  
  
  
  include_tool_output: false
  truncate_tools: true